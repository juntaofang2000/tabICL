# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
# SPDX-License-Identifier: Apache-2.0

# The kernel-synth method is available at: we took this snippet from there.
# https://github.com/amazon-science/chronos-forecasting

import functools
from typing import Optional

import numpy as np
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import (
    RBF,
    ConstantKernel,
    DotProduct,
    ExpSineSquared,
    Kernel,
    RationalQuadratic,
    WhiteKernel,
)

LENGTH = 512
KERNEL_BANK = [
    ExpSineSquared(periodicity=24 / LENGTH / 2),  # H
    ExpSineSquared(periodicity=48 / LENGTH / 2),  # 0.5H
    ExpSineSquared(periodicity=96 / LENGTH / 2),  # 0.25H
    ExpSineSquared(periodicity=24 * 7 / LENGTH / 2),  # H
    ExpSineSquared(periodicity=48 * 7 / LENGTH / 2),  # 0.5H
    ExpSineSquared(periodicity=96 * 7 / LENGTH / 2),  # 0.25H
    ExpSineSquared(periodicity=7 / LENGTH / 2),  # D
    ExpSineSquared(periodicity=14 / LENGTH / 2),  # 0.5D
    ExpSineSquared(periodicity=30 / LENGTH / 2),  # D
    ExpSineSquared(periodicity=60 / LENGTH / 2),  # 0.5D
    ExpSineSquared(periodicity=365 / LENGTH / 2),  # D
    ExpSineSquared(periodicity=365 * 2 / LENGTH / 2),  # 0.5D
    ExpSineSquared(periodicity=4 / LENGTH / 2),  # W
    ExpSineSquared(periodicity=26 / LENGTH / 2),  # W
    ExpSineSquared(periodicity=52 / LENGTH / 2),  # W
    ExpSineSquared(periodicity=4 / LENGTH / 2),  # M
    ExpSineSquared(periodicity=6 / LENGTH / 2),  # M
    ExpSineSquared(periodicity=12 / LENGTH / 2),  # M
    ExpSineSquared(periodicity=4 / LENGTH / 2),  # Q
    ExpSineSquared(periodicity=4 * 10 / LENGTH / 2),  # Q
    ExpSineSquared(periodicity=10 / LENGTH / 2),  # Y
    DotProduct(sigma_0=0.0),
    DotProduct(sigma_0=1.0),
    DotProduct(sigma_0=10.0),
    RBF(length_scale=0.1),
    RBF(length_scale=1.0),
    RBF(length_scale=10.0),
    RationalQuadratic(alpha=0.1),
    RationalQuadratic(alpha=1.0),
    RationalQuadratic(alpha=10.0),
    WhiteKernel(noise_level=0.1),
    WhiteKernel(noise_level=1.0),
    ConstantKernel(),
]


def random_binary_map(a: Kernel, b: Kernel):
    """
    Applies a random binary operator (+ or *) with equal probability
    on kernels ``a`` and ``b``.

    Parameters
    ----------
    a
        A GP kernel.
    b
        A GP kernel.

    Returns
    -------
        The composite kernel `a + b` or `a * b`.
    """
    binary_maps = [lambda x, y: x + y, lambda x, y: x * y]
    return np.random.choice(binary_maps)(a, b)


def sample_from_gp_prior(
    kernel: Kernel, X: np.ndarray, random_seed: Optional[int] = None
):
    """
    Draw a sample from a GP prior.

    Parameters
    ----------
    kernel
        The GP covaraince kernel.
    X
        The input "time" points.
    random_seed, optional
        The random seed for sampling, by default None.

    Returns
    -------
        A time series sampled from the GP prior.
    """
    if X.ndim == 1:
        X = X[:, None]

    assert X.ndim == 2
    gpr = GaussianProcessRegressor(kernel=kernel)
    ts = gpr.sample_y(X, n_samples=1, random_state=random_seed)

    return ts


def sample_from_gp_prior_efficient(
    kernel: Kernel,
    X: np.ndarray,
    random_seed: Optional[int] = None,
    method: str = "cholesky",
):
    """
    Draw a sample from a GP prior. An efficient version that allows specification
    of the sampling method. The default sampling method used in GaussianProcessRegressor
    is based on SVD which is significantly slower that alternatives such as `eigh` and
    `cholesky`.

    Parameters
    ----------
    kernel
        The GP covaraince kernel.
    X
        The input "time" points.
    random_seed, optional
        The random seed for sampling, by default None.
    method, optional
        The sampling method for multivariate_normal, by default `eigh`.

    Returns
    -------
        A time series sampled from the GP prior.
    """
    if X.ndim == 1:
        X = X[:, None]

    assert X.ndim == 2

    cov = kernel(X)
    jitter = 1e-6 * np.eye(X.shape[0])
    cov += jitter
    ts = np.random.default_rng(seed=random_seed).multivariate_normal(
        mean=np.zeros(X.shape[0]), cov=cov, method=method
    )

    return ts


def generate_time_series(max_kernels: int = 5):
    """Generate a synthetic time series from KernelSynth.

    Parameters
    ----------
    max_kernels, optional
        The maximum number of base kernels to use for each time series, by default 5

    Returns
    -------
        A time series generated by KernelSynth.
    """
    while True:
        X = np.linspace(0, 1, LENGTH)

        # Randomly select upto max_kernels kernels from the KERNEL_BANK
        selected_kernels = np.random.choice(
            KERNEL_BANK, np.random.randint(1, max_kernels + 1), replace=True
        )

        # Combine the sampled kernels using random binary operators
        kernel = functools.reduce(random_binary_map, selected_kernels)

        # Sample a time series from the GP prior
        try:
            # ts = sample_from_gp_prior(kernel=kernel, X=X)
            ts = sample_from_gp_prior_efficient(kernel=kernel, X=X)
        except np.linalg.LinAlgError as err:
            print("Error caught:", err)
            continue

        # The timestamp is arbitrary
        return {"start": np.datetime64("2000-01-01 00:00", "s"), "target": ts.squeeze()}

